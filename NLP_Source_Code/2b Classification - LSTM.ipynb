{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJDugh9g7sqj",
    "outputId": "7abf3f43-a724-417b-c6b4-1a815849c638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  3 10:51:04 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   65C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mfJ-fHlufJCo"
   },
   "outputs": [],
   "source": [
    "!pip install -qq tensorflow==2.9.0\n",
    "!pip install -qq keras==2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gXPfsoF_mZ5",
    "outputId": "e9a05193-2653-49c4-cb96-029f6820de72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "p_stemmer = PorterStemmer() # initialize PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "16iMmY7FM43N"
   },
   "outputs": [],
   "source": [
    "URL_BASE = 'https://raw.githubusercontent.com/xiao-yangg/CE4045-NLP/main/'\n",
    "filenames = ['apple_sentiment_online_filtered.csv', 'combined_dataset.csv', 'test_dataset.csv', 'training_dataset.csv', 'twitter_tweets_filtered.csv', 'us_airline_filtered.csv', 'original label.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CnGH3AUzOvcF"
   },
   "outputs": [],
   "source": [
    "tsds = pd.read_csv(URL_BASE + 'test_dataset.csv')\n",
    "trds = pd.read_csv(URL_BASE + 'training_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V36bdSr4PbMs"
   },
   "outputs": [],
   "source": [
    "tsds.rename(columns={'final_label': 'sentiment'}, inplace=True)\n",
    "trds.rename(columns={'final_label': 'sentiment'}, inplace=True)\n",
    "\n",
    "tsds.drop_duplicates(['tweet'], inplace=True)\n",
    "trds.drop_duplicates(['tweet'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6WmEHu-97KQU"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Stemming\n",
    "def stemming(token_list):\n",
    "    stemmed_list = []\n",
    "    for word in token_list:\n",
    "        stemmed_list.append(p_stemmer.stem(word))\n",
    "    return stemmed_list\n",
    "\n",
    "# Lemmatization\n",
    "def lemmatization(stemmed_list):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemma_list = []\n",
    "    for word in stemmed_list:\n",
    "        lemma_list.append(wordnet_lemmatizer.lemmatize(word))\n",
    "    return lemma_list\n",
    "\n",
    "# Removal of Stopwords\n",
    "def remove_stopword(text):\n",
    "    nltk_tokenList = tokenize(text) # tokenize\n",
    "\n",
    "    filtered_sentence = [] # sentence without stopwords\n",
    "    nltk_stop_words = set(stopwords.words(\"english\"))\n",
    "    for w in nltk_tokenList:  \n",
    "        if w not in nltk_stop_words:  \n",
    "            filtered_sentence.append(w)\n",
    "    \n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "# Combination of stemming and lemmatization\n",
    "def nltk_process(text):\n",
    "    nltk_tokenList = tokenize(text) # tokenize\n",
    "    nltk_stemmedList = stemming(nltk_tokenList) # stemmed\n",
    "    nltk_lemmaList = lemmatization(nltk_stemmedList) # lemma\n",
    "    return ' '.join(nltk_lemmaList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3zki7Rvw7Mqz"
   },
   "outputs": [],
   "source": [
    "def normalize_df(df):    \n",
    "    df['tweet'] = df['tweet'].apply(remove_stopword) # obtain tweet without stopwords\n",
    "    df['tweet'] = df['tweet'].apply(nltk_process) # tweet with no stopwords go through stemming and lemma\n",
    "\n",
    "    # New dataframe of text normalized tweets\n",
    "    columns_titles = ['tweet','sentiment']\n",
    "    return df.reindex(columns=columns_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ybdh6Wr6YVQx"
   },
   "outputs": [],
   "source": [
    "tsds = normalize_df(tsds)\n",
    "trds = normalize_df(trds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "APb5lLLjUcsS"
   },
   "outputs": [],
   "source": [
    "all_train_tweets = trds['tweet'].copy()\n",
    "all_train_tweets = all_train_tweets.append(tsds['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OfgvNRtZ7ne",
    "outputId": "a76e2f35-8105-4fca-f2ce-cc37ed24383a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16504,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8SK-iFFfWFuU"
   },
   "outputs": [],
   "source": [
    "max_words = 8000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(all_train_tweets.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "erwTgAWgh6-J"
   },
   "outputs": [],
   "source": [
    "def build_datasets(df):\n",
    "  df_0 = df[df['sentiment'] == 'NEGATIVE']\n",
    "  df_1 = df[df['sentiment'] == 'NEUTRAL']\n",
    "  df_2 = df[df['sentiment'] == 'POSITIVE']\n",
    "\n",
    "  df_0.iloc[:, 1] = 1\n",
    "  df_1.iloc[:, 1] = 0\n",
    "  df_2.iloc[:, 1] = 1\n",
    "  df_SUB = shuffle(pd.concat([df_0, df_1, df_2]).copy())\n",
    "\n",
    "  df_0.iloc[:, 1] = 0\n",
    "  df_2.iloc[:, 1] = 1\n",
    "  df_POL = shuffle(pd.concat([df_0, df_1, df_2]).copy())\n",
    "  return df_SUB, df_POL, df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChOukzo7pG8C",
    "outputId": "78673108-ab94-49d5-fa59-fc5eaeae5e69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[selected_item_labels] = value\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "tsds_SUB, tsds_POL, tsds_NEU = build_datasets(tsds)\n",
    "trds_SUB, trds_POL, trds_NEU = build_datasets(trds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WvIl9ALFZfK7"
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(trds['tweet'].values)\n",
    "X2 = pad_sequences(sequences, maxlen=max_len)\n",
    "Y2 = pd.get_dummies(trds['sentiment']).values\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(tsds['tweet'].values)\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "Y = pd.get_dummies(tsds['sentiment']).values\n",
    "\n",
    "X5, X6, Y5, Y6 = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BtKzYfUqWJdY"
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(max_words, 20)) # The embedding layer\n",
    "model1.add(layers.LSTM(15, dropout=0.1)) # Our LSTM layer\n",
    "model1.add(layers.Dense(3, activation='softmax'))\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "earlystopping1 = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OyY4P1oeaULs",
    "outputId": "ab643c29-cf71-4a4c-8568-58bbf335c8cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "366/366 [==============================] - 12s 14ms/step - loss: 0.8132 - accuracy: 0.6401 - val_loss: 1.1832 - val_accuracy: 0.5100\n",
      "Epoch 2/100\n",
      "366/366 [==============================] - 4s 12ms/step - loss: 0.4725 - accuracy: 0.8309 - val_loss: 1.0838 - val_accuracy: 0.5708\n",
      "Epoch 3/100\n",
      "366/366 [==============================] - 5s 14ms/step - loss: 0.3235 - accuracy: 0.8894 - val_loss: 1.0516 - val_accuracy: 0.6692\n",
      "Epoch 4/100\n",
      "366/366 [==============================] - 5s 12ms/step - loss: 0.2271 - accuracy: 0.9293 - val_loss: 1.1700 - val_accuracy: 0.6892\n",
      "Epoch 5/100\n",
      "366/366 [==============================] - 4s 12ms/step - loss: 0.1723 - accuracy: 0.9475 - val_loss: 1.2564 - val_accuracy: 0.6933\n",
      "Epoch 6/100\n",
      "366/366 [==============================] - 5s 12ms/step - loss: 0.1376 - accuracy: 0.9609 - val_loss: 1.4175 - val_accuracy: 0.6992\n",
      "Epoch 7/100\n",
      "366/366 [==============================] - 5s 13ms/step - loss: 0.1184 - accuracy: 0.9668 - val_loss: 1.5236 - val_accuracy: 0.7025\n",
      "Epoch 8/100\n",
      "366/366 [==============================] - 4s 12ms/step - loss: 0.1030 - accuracy: 0.9709 - val_loss: 1.5683 - val_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "366/366 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9732Restoring model weights from the end of the best epoch: 7.\n",
      "366/366 [==============================] - 5s 13ms/step - loss: 0.0943 - accuracy: 0.9732 - val_loss: 1.7812 - val_accuracy: 0.6925\n",
      "Epoch 9: early stopping\n",
      "CPU times: user 49.4 s, sys: 3.9 s, total: 53.3 s\n",
      "Wall time: 49.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model1.fit(X2, Y2, epochs=100, validation_data=[X6, Y6], callbacks=[earlystopping1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q45nrZbhTXU8",
    "outputId": "440672e0-af33-4f35-ce38-722768d51e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.9114 - accuracy: 0.6656 - val_loss: 0.7304 - val_accuracy: 0.7025\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 3s 24ms/step - loss: 0.6284 - accuracy: 0.7500 - val_loss: 0.6910 - val_accuracy: 0.7208\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 0.5120 - accuracy: 0.8042 - val_loss: 0.6850 - val_accuracy: 0.7325\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.4152 - accuracy: 0.8514 - val_loss: 0.6994 - val_accuracy: 0.7300\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.3427 - accuracy: 0.8800 - val_loss: 0.7644 - val_accuracy: 0.7408\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.2852 - accuracy: 0.9006 - val_loss: 0.7816 - val_accuracy: 0.7350\n",
      "Epoch 7/100\n",
      "111/113 [============================>.] - ETA: 0s - loss: 0.2433 - accuracy: 0.9130Restoring model weights from the end of the best epoch: 5.\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 0.2433 - accuracy: 0.9128 - val_loss: 0.8291 - val_accuracy: 0.7350\n",
      "Epoch 7: early stopping\n",
      "CPU times: user 13.7 s, sys: 943 ms, total: 14.6 s\n",
      "Wall time: 51.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model1.fit(X5, Y5, epochs=100, validation_data=[X6, Y6], callbacks=[earlystopping1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3Rvhh6JRGwd",
    "outputId": "7c5f63c8-a7a9-4ef7-bb90-a36fddd6fcf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 14ms/step - loss: 0.7644 - accuracy: 0.7408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7644030451774597, 0.7408333420753479]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X6, Y6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "au7tW7tem-3m"
   },
   "outputs": [],
   "source": [
    "# text = 'applewatch hello!'.lower()\n",
    "# text = remove_stopword(text)\n",
    "# text = nltk_process(text)\n",
    "# temp_sequences = tokenizer.texts_to_sequences([text])\n",
    "# temp_X = pad_sequences(temp_sequences, maxlen=max_len)\n",
    "# model1.predict(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Rh0SzTSTrLBL"
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(trds_SUB['tweet'].values)\n",
    "X2_SUB = pad_sequences(sequences, maxlen=max_len)\n",
    "Y2_SUB = pd.get_dummies(trds_SUB['sentiment']).values\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(tsds_SUB['tweet'].values)\n",
    "X_SUB = pad_sequences(sequences, maxlen=max_len)\n",
    "Y_SUB = pd.get_dummies(tsds_SUB['sentiment']).values\n",
    "\n",
    "X5_SUB, X6_SUB, Y5_SUB, Y6_SUB = train_test_split(X_SUB, Y_SUB, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nGR0FVLyrCpU"
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(layers.Embedding(max_words, 20)) # The embedding layer\n",
    "model2.add(layers.Bidirectional(layers.LSTM(15, dropout=0.1))) # Our LSTM layer\n",
    "model2.add(layers.Dense(2, activation='softmax'))\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "earlystopping2 = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODk5dlImsDzV",
    "outputId": "54a9bc76-fa1a-46b5-fd83-bfaffcadf077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "366/366 [==============================] - 14s 24ms/step - loss: 0.5112 - accuracy: 0.7427 - val_loss: 0.5929 - val_accuracy: 0.7250\n",
      "Epoch 2/100\n",
      "366/366 [==============================] - 8s 21ms/step - loss: 0.2371 - accuracy: 0.9159 - val_loss: 0.6422 - val_accuracy: 0.7625\n",
      "Epoch 3/100\n",
      "366/366 [==============================] - 9s 25ms/step - loss: 0.1528 - accuracy: 0.9525 - val_loss: 0.7551 - val_accuracy: 0.7758\n",
      "Epoch 4/100\n",
      "366/366 [==============================] - 8s 21ms/step - loss: 0.1182 - accuracy: 0.9643 - val_loss: 0.9145 - val_accuracy: 0.7817\n",
      "Epoch 5/100\n",
      "366/366 [==============================] - 8s 21ms/step - loss: 0.1008 - accuracy: 0.9706 - val_loss: 0.8678 - val_accuracy: 0.7908\n",
      "Epoch 6/100\n",
      "366/366 [==============================] - 7s 20ms/step - loss: 0.0881 - accuracy: 0.9751 - val_loss: 1.0741 - val_accuracy: 0.7925\n",
      "Epoch 7/100\n",
      "366/366 [==============================] - 8s 21ms/step - loss: 0.0821 - accuracy: 0.9760 - val_loss: 1.0518 - val_accuracy: 0.7967\n",
      "Epoch 8/100\n",
      "366/366 [==============================] - 8s 21ms/step - loss: 0.0777 - accuracy: 0.9775 - val_loss: 1.0938 - val_accuracy: 0.7992\n",
      "Epoch 9/100\n",
      "366/366 [==============================] - 8s 21ms/step - loss: 0.0724 - accuracy: 0.9803 - val_loss: 1.0837 - val_accuracy: 0.7958\n",
      "Epoch 10/100\n",
      "366/366 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9825Restoring model weights from the end of the best epoch: 8.\n",
      "366/366 [==============================] - 9s 26ms/step - loss: 0.0653 - accuracy: 0.9825 - val_loss: 1.1122 - val_accuracy: 0.7967\n",
      "Epoch 10: early stopping\n",
      "CPU times: user 1min 32s, sys: 6.45 s, total: 1min 38s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model2.fit(X2_SUB, Y2_SUB, epochs=100, validation_data=[X6_SUB, Y6_SUB], callbacks=[earlystopping1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVHGEcHvsJR3",
    "outputId": "06775d14-ba1c-4ef5-db0f-463fdb6e3d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - 3s 24ms/step - loss: 0.5092 - accuracy: 0.7964 - val_loss: 0.4022 - val_accuracy: 0.8258\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 0.3242 - accuracy: 0.8653 - val_loss: 0.4079 - val_accuracy: 0.8283\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 0.2684 - accuracy: 0.8983 - val_loss: 0.4223 - val_accuracy: 0.8275\n",
      "Epoch 4/100\n",
      "111/113 [============================>.] - ETA: 0s - loss: 0.2204 - accuracy: 0.9192Restoring model weights from the end of the best epoch: 2.\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 0.2195 - accuracy: 0.9192 - val_loss: 0.4645 - val_accuracy: 0.8225\n",
      "Epoch 4: early stopping\n",
      "CPU times: user 11.6 s, sys: 920 ms, total: 12.6 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model2.fit(X5_SUB, Y5_SUB, epochs=100, validation_data=[X6_SUB, Y6_SUB], callbacks=[earlystopping1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A72W3sDRsUp-",
    "outputId": "29572a61-1e0a-419c-b945-b5f074b97f33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 12ms/step - loss: 0.4079 - accuracy: 0.8283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4078553020954132, 0.82833331823349]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X6_SUB, Y6_SUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "i-hAYdgurkll"
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(trds_POL['tweet'].values)\n",
    "X2_POL = pad_sequences(sequences, maxlen=max_len)\n",
    "Y2_POL = pd.get_dummies(trds_POL['sentiment']).values\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(tsds_POL['tweet'].values)\n",
    "X_POL = pad_sequences(sequences, maxlen=max_len)\n",
    "Y_POL = pd.get_dummies(tsds_POL['sentiment']).values\n",
    "\n",
    "X5_POL, X6_POL, Y5_POL, Y6_POL = train_test_split(X_POL, Y_POL, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KuDRvmysr17P"
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(layers.Embedding(max_words, 20)) # The embedding layer\n",
    "model3.add(layers.Bidirectional(layers.LSTM(15, dropout=0.1))) # Our LSTM layer\n",
    "model3.add(layers.Dense(2, activation='softmax'))\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "earlystopping3 = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4mjw1Uht13G",
    "outputId": "501e5409-edc0-4174-adc6-3a8c46a73084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "366/366 [==============================] - 12s 23ms/step - loss: 0.5213 - accuracy: 0.7245 - val_loss: 0.6819 - val_accuracy: 0.7250\n",
      "Epoch 2/100\n",
      "366/366 [==============================] - 7s 20ms/step - loss: 0.2531 - accuracy: 0.9080 - val_loss: 0.7612 - val_accuracy: 0.7317\n",
      "Epoch 3/100\n",
      "366/366 [==============================] - 7s 20ms/step - loss: 0.1791 - accuracy: 0.9400 - val_loss: 0.7361 - val_accuracy: 0.7433\n",
      "Epoch 4/100\n",
      "366/366 [==============================] - 9s 24ms/step - loss: 0.1471 - accuracy: 0.9526 - val_loss: 0.9712 - val_accuracy: 0.7575\n",
      "Epoch 5/100\n",
      "366/366 [==============================] - 7s 20ms/step - loss: 0.1232 - accuracy: 0.9613 - val_loss: 0.9519 - val_accuracy: 0.7650\n",
      "Epoch 6/100\n",
      "366/366 [==============================] - 8s 21ms/step - loss: 0.1046 - accuracy: 0.9678 - val_loss: 1.0607 - val_accuracy: 0.7608\n",
      "Epoch 7/100\n",
      "366/366 [==============================] - 7s 20ms/step - loss: 0.0908 - accuracy: 0.9721 - val_loss: 1.1236 - val_accuracy: 0.7725\n",
      "Epoch 8/100\n",
      "366/366 [==============================] - 7s 20ms/step - loss: 0.0798 - accuracy: 0.9755 - val_loss: 1.1250 - val_accuracy: 0.7683\n",
      "Epoch 9/100\n",
      "364/366 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9793Restoring model weights from the end of the best epoch: 7.\n",
      "366/366 [==============================] - 8s 21ms/step - loss: 0.0677 - accuracy: 0.9794 - val_loss: 1.1847 - val_accuracy: 0.7725\n",
      "Epoch 9: early stopping\n",
      "CPU times: user 1min 18s, sys: 5.77 s, total: 1min 24s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model3.fit(X2_POL, Y2_POL, epochs=100, validation_data=[X6_POL, Y6_POL], callbacks=[earlystopping1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49Ff8OsDt7t4",
    "outputId": "d84ab09a-580a-477b-ec77-4dba51e6acff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 0.5921 - accuracy: 0.7628 - val_loss: 0.4991 - val_accuracy: 0.7717\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 0.3886 - accuracy: 0.8267 - val_loss: 0.4975 - val_accuracy: 0.7842\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 0.3034 - accuracy: 0.8711 - val_loss: 0.5183 - val_accuracy: 0.7825\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 0.2396 - accuracy: 0.9025 - val_loss: 0.5369 - val_accuracy: 0.7917\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 0.1890 - accuracy: 0.9264 - val_loss: 0.5838 - val_accuracy: 0.7900\n",
      "Epoch 6/100\n",
      "112/113 [============================>.] - ETA: 0s - loss: 0.1504 - accuracy: 0.9448Restoring model weights from the end of the best epoch: 4.\n",
      "113/113 [==============================] - 3s 25ms/step - loss: 0.1508 - accuracy: 0.9447 - val_loss: 0.6138 - val_accuracy: 0.7850\n",
      "Epoch 6: early stopping\n",
      "CPU times: user 17.2 s, sys: 1.31 s, total: 18.5 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model3.fit(X5_POL, Y5_POL, epochs=100, validation_data=[X6_POL, Y6_POL], callbacks=[earlystopping1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njZBCeeduBp4",
    "outputId": "5010effc-acae-4b17-ee1f-a6c2bf169941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 15ms/step - loss: 0.5369 - accuracy: 0.7917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5368744134902954, 0.7916666865348816]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X6_POL, Y6_POL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
